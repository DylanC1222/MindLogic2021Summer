{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b78275f-ee04-4100-81b9-36b4e79f45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import csv\n",
    "import string\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ebcec6-81af-46c2-8ca6-b60f2ea3bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need tensorflow, tensorflow_hub, numpy, psycopg2, pandas, and sklearn\n",
    "# All of these packages should be downloadable with pip\n",
    "\n",
    "# connect to the PostgreSQL database server\n",
    "def connect(params_dic):\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(**params_dic)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedb15f3-01b0-4546-8b12-1dc0752a5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert postgresql db to pandas df\n",
    "def postgresql_to_dataframe(conn, select_query, column_names):\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(select_query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    \n",
    "    # Naturally we get a list of tupples\n",
    "    tupples = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    \n",
    "    # We just need to turn it into a pandas dataframe\n",
    "    df = pd.DataFrame(tupples, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8a5444-9e4f-44d4-a775-ae362a41d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection parameters\n",
    "param_dic = {\n",
    "    \"host\"      : \"ec2-3-35-78-167.ap-northeast-2.compute.amazonaws.com\",\n",
    "    \"database\"  : \"postgres\",\n",
    "    \"user\"      : \"postgres\",\n",
    "    \"password\"  : \"postgres\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4028c69-7a25-4338-ba8f-d257c353a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = connect(param_dic)\n",
    "\n",
    "df = postgresql_to_dataframe(conn, \"select text from fb_mychatbot_chat where said_by='USR'\", ['text'])\n",
    "df = df['text']\n",
    "df = df.astype('str')\n",
    "np_messages = df.to_numpy()\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "embed = hub.load(module_url)\n",
    "prelim_sent_list = []\n",
    "freq_list = []\n",
    "sentences_dict = {}\n",
    "sentences_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e78194-df1f-4e22-8e39-a50e09cdd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing all of the responses and recording number of times each response came up\n",
    "for i in np_messages:\n",
    "    i = i.lower()\n",
    "    i = i.translate(str.maketrans('', '', string.punctuation))\n",
    "    if i.isspace():\n",
    "        continue\n",
    "    if len(i) == 0:\n",
    "        continue\n",
    "    if i in sentences_dict:\n",
    "        sentences_dict[i] = sentences_dict[i] + 1\n",
    "    else:\n",
    "        sentences_dict[i] = 1\n",
    "        prelim_sent_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e894a8-8427-4afa-8004-6f66c7dc45ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of messages with freq 1 is 14638\n"
     ]
    }
   ],
   "source": [
    "# This is supposed to be used to get rid of all of the responses that are of a lower frequency.\n",
    "\n",
    "# Finds the frequency of all of the sentences\n",
    "for key in sentences_dict:\n",
    "    freq_list.append(sentences_dict[key])\n",
    "\n",
    "npfreq = np.array(freq_list)\n",
    "\n",
    "cutoff_freq = np.percentile(npfreq, 95)\n",
    "\n",
    "count = 0\n",
    "for sent in prelim_sent_list:\n",
    "    if sentences_dict[sent] == 1:\n",
    "        count += 1\n",
    "print(\"the number of messages with freq 1 is \"+str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2c0353-591b-4317-b500-5a210942fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only adds sentences that are in the top 5% most frequent responses\n",
    "for sent in prelim_sent_list:\n",
    "    if sentences_dict[sent] > cutoff_freq:\n",
    "        sentences_list.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9803829-720b-4d37-936b-700950b53854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE at work\n",
    "embeddings = embed(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "996999be-19e7-4b7c-b364-791b97c91c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding a more granular cluster_cnt\n",
    "cluster_cnt = 1\n",
    "for i in range(len(sentences_list)):\n",
    "    granular = len(sentences_list) / cluster_cnt\n",
    "    if granular <= 1.6:\n",
    "        break\n",
    "    else:\n",
    "        cluster_cnt += 2\n",
    "        \n",
    "CLUSTER_CNT = int(cluster_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752d8c00-ca79-4f6c-97e0-99763d6e47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering the data that went through the USE\n",
    "kmeans = KMeans(n_clusters = CLUSTER_CNT)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "labelDict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51095af1-411e-4628-98c3-04159b72baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputting the clustered data into a dictionary\n",
    "for i, sentence in enumerate(sentences_list):\n",
    "    if labels[i] in labelDict.keys():\n",
    "        labelDict[labels[i]].append(sentence)\n",
    "    else:\n",
    "        labelDict[labels[i]] = [sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28768163-0f94-42d9-a2c3-4141350fd84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering the cluster numberings to output the clusters from 0 to CLUSTER_CNT - 1\n",
    "cluster_id = []\n",
    "for label in labelDict.keys():\n",
    "    cluster_id.append(label)\n",
    "cluster_id.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b645d235-71ca-4782-b304-78d2ab413a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing out the information into a CSV file for reading by typist\n",
    "# If you have provided a statement, then that specific cluster will be outputted\n",
    "\n",
    "with open('fbmchat_output.csv', mode='w') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['cluster', 'frequency', 'message'])\n",
    "    for label in cluster_id:\n",
    "        for sentence in labelDict[label]:\n",
    "            writer.writerow([label, sentences_dict[sentence], sentence])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
